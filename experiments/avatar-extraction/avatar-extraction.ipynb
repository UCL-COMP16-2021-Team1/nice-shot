{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f4d121ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\users\\chung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.8.9.1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\chung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.5.5.62)\n",
      "Requirement already satisfied: absl-py in c:\\users\\chung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (1.0.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\chung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (3.5.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\chung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (1.22.0)\n",
      "Requirement already satisfied: protobuf>=3.11.4 in c:\\users\\chung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (3.19.1)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\chung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (21.4.0)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\users\\chung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from mediapipe) (4.5.5.62)\n",
      "Requirement already satisfied: six in c:\\users\\chung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from absl-py->mediapipe) (1.16.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\chung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mediapipe) (1.3.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\chung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mediapipe) (9.0.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\chung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mediapipe) (4.28.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\chung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\chung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\chung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mediapipe) (21.3)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\chung\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib->mediapipe) (3.0.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\chung\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install mediapipe opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c20cbf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec6fbb2",
   "metadata": {},
   "source": [
    "Code below prints the coordinates of the extracted 3D model for each frame of the video.\n",
    "The order in which the coordinates are printed are: nose, left elbow, left foot, left wrist, left hip, left knee, left shoulder, neck, right elbow, right foot, right wrist, right hip, right knee, right shoulder, torso\n",
    "\n",
    "Mediapipe doesn't normally have the neck and torso coordinates estimated so the neck coordinates is calculated by calculating the mid point between the left and right shoulder.\n",
    "Same with the torso which is calculated by finding the midpoint of the left and right shoulder as well as the right and left hip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "84050510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n",
      "landmark\n",
      "after\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(\"p1_backhand_s2.mp4\")\n",
    "\n",
    "def frameCoordinates(landmarks, f):\n",
    "    joints = [0,13,31,15,23,25,11,\"neck\",14,32,16,24,26,12,\"torso\"]\n",
    "    for i in joints:\n",
    "        if i == \"neck\":\n",
    "            neckX = (landmarks[11].x + landmarks[12].x)/2\n",
    "            neckY = (landmarks[11].y + landmarks[12].y)/2\n",
    "            neckZ = (landmarks[11].z + landmarks[12].z)/2\n",
    "            f.write(str(neckX) + \" \" + str(neckY) + \" \" + str(neckZ))\n",
    "            f.write('\\n')\n",
    "        elif i == \"torso\":\n",
    "            torsoX = (landmarks[11].x + landmarks[24].x)/2\n",
    "            torsoY = (landmarks[11].y + landmarks[24].y)/2\n",
    "            torsoZ = (landmarks[11].z + landmarks[24].z)/2\n",
    "            f.write(str(torsoX) + \" \" + str(torsoY) + \" \" + str(torsoZ))\n",
    "            f.write('\\n')\n",
    "            \n",
    "        else:\n",
    "            f.write(str(landmarks[i].x) + \" \" + str(landmarks[i].y) + \" \" + str(landmarks[i].z))\n",
    "            f.write('\\n')\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    frameCounter = 0\n",
    "    with open(\"joints.txt\", 'w') as f:\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if ret == True:\n",
    "\n",
    "                image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                image.flags.writeable = False\n",
    "\n",
    "                # Make detection\n",
    "                results = pose.process(image)\n",
    "\n",
    "                # Recolor back to BGR\n",
    "                image.flags.writeable = True\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                try:\n",
    "                    landmarks = results.pose_landmarks.landmark\n",
    "                    print(\"landmark\")\n",
    "                    f.write(\"Frame: \" + str(frameCounter))\n",
    "                    f.write('\\n')\n",
    "                    print(\"after\")\n",
    "                    frameCoordinates(landmarks, f)\n",
    "                    frameCounter += 1\n",
    "\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                # Render detections\n",
    "                mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)               \n",
    "\n",
    "                cv2.imshow('Mediapipe Feed', image)\n",
    "\n",
    "\n",
    "                if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "    f.close()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
