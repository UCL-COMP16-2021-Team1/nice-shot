{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN-based 3D Skeleton Tennis Shot Recognition\n",
    "\n",
    "Based on method from paper ['Skeleton-based Action Recognition with Convolutional Neural Networks'](https://arxiv.org/abs/1704.07595) by Li et al. (2017).\n",
    "\n",
    "We use the 3D skeletal animation data from the ['THETIS'](http://thetis.image.ece.ntua.gr/) dataset for training. Each animation is represented as a `T x N` 3-channel image where `T` is the number of frames of the animation, `N` is the number of skeletal joints, and the 3 colour channels represent `x, y, z` coordinates of the joints."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also use the motion data, represented in the same image format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the skeleton and motion images training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 621 files belonging to 12 classes.\n",
      "Using 497 files for training.\n",
      "Found 621 files belonging to 12 classes.\n",
      "Using 497 files for training.\n",
      "Found 621 files belonging to 12 classes.\n",
      "Using 124 files for validation.\n",
      "Found 621 files belonging to 12 classes.\n",
      "Using 124 files for validation.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "skeleton_dir = \"data/skeleton_images\"\n",
    "motion_dir = \"data/motion_images\"\n",
    "\n",
    "img_height = 32\n",
    "img_width = 32\n",
    "batch_size = 32\n",
    "\n",
    "skeleton_train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  skeleton_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size\n",
    ")\n",
    "\n",
    "motion_train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  motion_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size\n",
    ")\n",
    "\n",
    "skeleton_val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  skeleton_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size\n",
    ")\n",
    "\n",
    "motion_val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "  motion_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size\n",
    ")\n",
    "\n",
    "skeleton_train_images = skeleton_train_ds.map(lambda img, label: img)\n",
    "motion_train_images = motion_train_ds.map(lambda img, label: img)\n",
    "train_images = tf.data.Dataset.zip((skeleton_train_images, motion_train_images))\n",
    "\n",
    "train_labels = skeleton_train_ds.map(lambda img, label: label)\n",
    "train_ds = tf.data.Dataset.zip((train_images, train_labels))\n",
    "\n",
    "skeleton_val_images = skeleton_val_ds.map(lambda img, label: img)\n",
    "motion_val_images = motion_val_ds.map(lambda img, label: img)\n",
    "val_images = tf.data.Dataset.zip((skeleton_val_images, motion_val_images))\n",
    "\n",
    "val_labels = skeleton_val_ds.map(lambda img, label: label)\n",
    "val_ds = tf.data.Dataset.zip((val_images, val_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\"\"\"\n",
    "skeleton_input = layers.Input(shape=(32,32,3))\n",
    "skeleton_rescale = layers.Rescaling(1./127.5, offset=-1)(skeleton_input)\n",
    "skeleton_conv1 = layers.Conv2D(32, (3,3), activation='relu')(skeleton_rescale)\n",
    "skeleton_pool1 = layers.MaxPooling2D((2,2))(skeleton_conv1)\n",
    "skeleton_conv2 = layers.Conv2D(64, (3,3), activation='relu')(skeleton_rescale)\n",
    "skeleton_pool2 = layers.MaxPooling2D((2,2))(skeleton_conv2)\n",
    "\"\"\"\n",
    "\n",
    "motion_input = layers.Input(shape=(250,15,3))\n",
    "motion_rescale = layers.Rescaling(1./127.5, offset=-1)(motion_input)\n",
    "motion_conv1 = layers.Conv2D(32, (3,3), activation='relu')(motion_rescale)\n",
    "motion_pool1 = layers.MaxPooling2D((2,2))(motion_conv1)\n",
    "motion_conv2 = layers.Conv2D(32, (3,3), activation='relu')(motion_pool1)\n",
    "motion_pool2 = layers.MaxPooling2D((2,2))(motion_conv2)\n",
    "\"\"\"\n",
    "concat = layers.Concatenate()([skeleton_pool, motion_pool])\n",
    "flatten = layers.Flatten()(concat)\n",
    "\"\"\"\n",
    "flatten = layers.Flatten()(motion_pool2)\n",
    "dense = layers.Dense(16, activation='relu')(flatten)\n",
    "softmax = layers.Dense(12, activation='softmax')(dense)\n",
    "\n",
    "#model = tf.keras.Model(inputs=[skeleton_input, motion_input], outputs=[softmax])\n",
    "model = tf.keras.Model(inputs=[motion_input], outputs=[softmax])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile and train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "16/16 [==============================] - 2s 72ms/step - loss: 2.4895 - accuracy: 0.0825 - val_loss: 2.4795 - val_accuracy: 0.1210\n",
      "Epoch 2/100\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 2.4627 - accuracy: 0.1388 - val_loss: 2.4563 - val_accuracy: 0.1048\n",
      "Epoch 3/100\n",
      "16/16 [==============================] - 1s 55ms/step - loss: 2.4098 - accuracy: 0.1247 - val_loss: 2.4069 - val_accuracy: 0.1452\n",
      "Epoch 4/100\n",
      "16/16 [==============================] - 1s 56ms/step - loss: 2.2889 - accuracy: 0.2133 - val_loss: 2.3226 - val_accuracy: 0.1774\n",
      "Epoch 5/100\n",
      "16/16 [==============================] - 1s 72ms/step - loss: 2.1448 - accuracy: 0.2736 - val_loss: 2.2672 - val_accuracy: 0.1613\n",
      "Epoch 6/100\n",
      "16/16 [==============================] - 1s 59ms/step - loss: 1.9975 - accuracy: 0.3199 - val_loss: 2.1794 - val_accuracy: 0.2097\n",
      "Epoch 7/100\n",
      "16/16 [==============================] - 1s 59ms/step - loss: 1.8154 - accuracy: 0.3924 - val_loss: 2.2072 - val_accuracy: 0.2258\n",
      "Epoch 8/100\n",
      "16/16 [==============================] - 1s 58ms/step - loss: 1.6636 - accuracy: 0.4266 - val_loss: 2.0938 - val_accuracy: 0.2097\n",
      "Epoch 9/100\n",
      "16/16 [==============================] - 1s 59ms/step - loss: 1.4715 - accuracy: 0.5272 - val_loss: 2.1373 - val_accuracy: 0.2258\n",
      "Epoch 10/100\n",
      "16/16 [==============================] - 1s 59ms/step - loss: 1.3645 - accuracy: 0.5292 - val_loss: 2.0274 - val_accuracy: 0.2823\n",
      "Epoch 11/100\n",
      "16/16 [==============================] - 1s 58ms/step - loss: 1.1689 - accuracy: 0.6398 - val_loss: 1.9828 - val_accuracy: 0.2661\n",
      "Epoch 12/100\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 1.0479 - accuracy: 0.6881 - val_loss: 2.0185 - val_accuracy: 0.3065\n",
      "Epoch 13/100\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 0.9078 - accuracy: 0.7223 - val_loss: 2.0383 - val_accuracy: 0.3226\n",
      "Epoch 14/100\n",
      "16/16 [==============================] - 1s 59ms/step - loss: 0.7645 - accuracy: 0.7887 - val_loss: 2.0817 - val_accuracy: 0.3306\n",
      "Epoch 15/100\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 0.6686 - accuracy: 0.8089 - val_loss: 2.1986 - val_accuracy: 0.2984\n",
      "Epoch 16/100\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 0.6125 - accuracy: 0.8209 - val_loss: 2.2022 - val_accuracy: 0.3468\n",
      "Epoch 17/100\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.5185 - accuracy: 0.8571 - val_loss: 2.2123 - val_accuracy: 0.3387\n",
      "Epoch 18/100\n",
      "16/16 [==============================] - 1s 57ms/step - loss: 0.4488 - accuracy: 0.8934 - val_loss: 2.2999 - val_accuracy: 0.3387\n",
      "Epoch 19/100\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.3867 - accuracy: 0.9115 - val_loss: 2.3375 - val_accuracy: 0.3629\n",
      "Epoch 20/100\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 0.3154 - accuracy: 0.9376 - val_loss: 2.5463 - val_accuracy: 0.3790\n",
      "Epoch 21/100\n",
      "16/16 [==============================] - 1s 59ms/step - loss: 0.2788 - accuracy: 0.9416 - val_loss: 2.5731 - val_accuracy: 0.3629\n",
      "Epoch 22/100\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.2374 - accuracy: 0.9598 - val_loss: 2.6231 - val_accuracy: 0.3145\n",
      "Epoch 23/100\n",
      "16/16 [==============================] - 1s 71ms/step - loss: 0.1849 - accuracy: 0.9799 - val_loss: 2.7570 - val_accuracy: 0.3226\n",
      "Epoch 24/100\n",
      "16/16 [==============================] - 1s 65ms/step - loss: 0.1565 - accuracy: 0.9819 - val_loss: 2.8677 - val_accuracy: 0.3226\n",
      "Epoch 25/100\n",
      "16/16 [==============================] - 1s 61ms/step - loss: 0.1359 - accuracy: 0.9819 - val_loss: 2.8678 - val_accuracy: 0.3226\n",
      "Epoch 26/100\n",
      "16/16 [==============================] - 1s 60ms/step - loss: 0.1218 - accuracy: 0.9899 - val_loss: 2.9934 - val_accuracy: 0.3145\n",
      "Epoch 27/100\n",
      "16/16 [==============================] - 1s 62ms/step - loss: 0.0947 - accuracy: 0.9960 - val_loss: 3.0714 - val_accuracy: 0.2903\n",
      "Epoch 28/100\n",
      "16/16 [==============================] - 1s 63ms/step - loss: 0.0803 - accuracy: 0.9940 - val_loss: 3.1773 - val_accuracy: 0.3145\n",
      "Epoch 29/100\n",
      "16/16 [==============================] - 1s 64ms/step - loss: 0.0705 - accuracy: 0.9960 - val_loss: 3.2755 - val_accuracy: 0.3226\n",
      "Epoch 30/100\n",
      " 5/16 [========>.....................] - ETA: 0s - loss: 0.0709 - accuracy: 0.9937"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-7b576864aa5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \"\"\"\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m model.fit(\n\u001b[0m\u001b[0;32m     13\u001b[0m   \u001b[0mmotion_train_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m   \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmotion_val_ds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['accuracy'])\n",
    "\"\"\"\n",
    "model.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=100\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "model.fit(\n",
    "  motion_train_ds,\n",
    "  validation_data=motion_val_ds,\n",
    "  epochs=100\n",
    ")\n",
    "\n",
    "model.save('cnn_recognition_model.h5')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c214f4d2c295345fdc57900708451324837b7865065ae46ceb283a6c9824d5d4"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
